{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Teste completo: Baseline CNN vs Híbrido CNN+VQC (Colab + GPU)\n",
        "\n",
        "Este notebook roda no **Google Colab** com GPU para replicar a comparação do artigo (Pereira & Saraiva, 2021):\n",
        "- **Baseline:** 3 runs × 100 épocas, cenários No Balance e ROS (altere N_RUNS_* na célula 5 para 10 se quiser replicar o artigo).\n",
        "- **Híbrido:** mesmo número de runs.\n",
        "\n",
        "**Antes de rodar:** ative o runtime com GPU (Runtime → Change runtime type → GPU)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### O que voce pode alterar no notebook\n",
        "\n",
        "**Rodar localmente:** Ative o venv (`source .venv/bin/activate`), instale com `pip install -r requirements.txt` na raiz do projeto, e abra o Jupyter na raiz ou em `notebooks/`. O notebook detecta a raiz e ajusta o path; o dataset vem do kagglehub ou defina `SGCC_DATASET_PATH`.\n",
        "\n",
        "1. **Celula de clone/setup:** Em Colab, clona o repo; localmente so define a raiz do projeto.\n",
        "\n",
        "2. **Credenciais (Colab/Kaggle):** Colab = Secrets (KAGGLE_USERNAME, KAGGLE_KEY). Local = `~/.kaggle/kaggle.json` ou `SGCC_DATASET_PATH` para a pasta do dataset.\n",
        "\n",
        "3. **Celula “Carregar dados e parametros”:**\n",
        "- **N_RUNS_BASELINE** e **N_RUNS_HYBRID** = 3. Use 10 para replicar o artigo.\n",
        "- **EPOCHS** = 100. Reduza (ex: 5) para teste rapido.\n",
        "- **SEEDS** = [0, 42, 123] para variedade por run.\n",
        "- **Dataset:** Colab/Kaggle ou env `SGCC_DATASET_PATH`; senao o notebook tenta baixar via kagglehub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Configurar ambiente e clonar o repositório"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tempo estimado e como nao desligar / nao desconectar\n",
        "\n",
        "**Tempo aproximado:** Com **3 runs × 2 cenários = 6 runs** por modelo (100 épocas):\n",
        "- **Baseline (GPU):** ~2–5 min por run → **~15–30 min** no total.\n",
        "- **Híbrido (CNN+VQC):** O VQC em si não é “lento”; o que pesa é **simular o circuito quântico na CPU** (PennyLane). Por run pode levar **~15–45 min** → com 3 runs, **~1h30–2h30** no total. Com 10 runs seria bem mais longo.\n",
        "\n",
        "Para teste ainda mais rápido: use menos épocas (ex: 5).\n",
        "\n",
        "**Para o PC nao desligar (rodando localmente no Linux):**\n",
        "- **Desativar suspensao:** Configuracoes → Energia → “Quando inativo” = Nunca (ou apenas desligar tela).\n",
        "- **Via terminal:** `systemctl mask sleep.target suspend.target hibernate.target hybrid-sleep.target` (reverter depois com `unmask`).\n",
        "- **Impedir que a tela bloqueie so durante o treino:** use `caffeinate` (macOS) ou no Linux algo como `xset s off; xset -dpms` antes de rodar (reverte depois com `xset s on; xset +dpms`), ou instale “Caffeine” / “Inhibit” no seu ambiente de desktop.\n",
        "\n",
        "**No Google Colab:**\n",
        "- O Colab pode desconectar apos ~90 min de inatividade. Mantenha a aba aberta e, se quiser, use um “keep-alive” no navegador (extensoes que simulam atividade) ou um script que rode em loop no console (ex: clicar no codigo a cada alguns minutos). Nao ha garantia; para runs muito longos, prefira rodar por partes (menos runs por vez) ou salvar checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificar GPU (TensorFlow usa automaticamente no Colab)\n",
        "import tensorflow as tf\n",
        "print(\"GPU disponível:\", tf.config.list_physical_devices('GPU'))\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Colab/Kaggle: clonar e entrar no repo. Local: usar raiz do projeto (notebooks/ ou repo).\n",
        "import os\n",
        "\n",
        "def _project_root():\n",
        "    cwd = os.path.abspath(os.getcwd())\n",
        "    for d in [cwd, os.path.join(cwd, \"..\"), os.path.join(cwd, \"..\", \"..\")]:\n",
        "        d = os.path.abspath(d)\n",
        "        if os.path.isdir(os.path.join(d, \"src\")) and os.path.isfile(os.path.join(d, \"train_baseline_pereira.py\")):\n",
        "            return d\n",
        "    return cwd\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    _in_colab = True\n",
        "except ImportError:\n",
        "    _in_colab = False\n",
        "_in_kaggle = bool(os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"))\n",
        "\n",
        "if _in_colab and not os.path.isdir(\"src\"):\n",
        "    get_ipython().system(\"git clone https://github.com/alanveloso/electricity-theft-hybrid-qml.git 2>/dev/null || true\")\n",
        "    get_ipython().run_line_magic(\"cd\", \"electricity-theft-hybrid-qml\")\n",
        "    print(\"Repositório clonado (Colab/Kaggle).\")\n",
        "else:\n",
        "    root = _project_root()\n",
        "    if root != os.getcwd():\n",
        "        os.chdir(root)\n",
        "        print(\"Raiz do projeto (local):\", root)\n",
        "    else:\n",
        "        print(\"Diretório atual:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalar dependências: Colab/Kaggle roda pip; local use o venv (pip install -r requirements.txt).\n",
        "if _in_colab or _in_kaggle:\n",
        "    get_ipython().system(\"pip install -q numpy pandas scikit-learn tensorflow kagglehub pennylane pennylane-lightning matplotlib\")\n",
        "else:\n",
        "    print(\"Ambiente local: use 'pip install -r requirements.txt' na raiz do projeto.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configurar Kaggle (dataset SGCC)\n",
        "\n",
        "Opção A: Colab Secrets - em Key adicione KAGGLE_USERNAME e KAGGLE_KEY (ou KAGGLE_API_TOKEN).\n",
        "Opção B: Faça upload do kaggle.json (Account, Create New Token no Kaggle) na célula abaixo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Kaggle: credenciais já disponíveis. Colab: usar Secrets. Local: kagglehub usa ~/.kaggle/kaggle.json ou env.\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    if os.environ.get(\"KAGGLE_KEY\") is None:\n",
        "        os.environ[\"KAGGLE_KEY\"] = userdata.get(\"KAGGLE_KEY\")\n",
        "    if os.environ.get(\"KAGGLE_USERNAME\") is None:\n",
        "        os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
        "    print(\"Credenciais Kaggle carregadas dos Secrets (Colab).\")\n",
        "except Exception as e:\n",
        "    if os.environ.get(\"KAGGLE_KERNEL_RUN_TYPE\"):\n",
        "        print(\"Kaggle: credenciais do ambiente.\")\n",
        "    else:\n",
        "        print(\"Secrets não configurados ou rodando localmente:\", e)\n",
        "        print(\"Local: configure ~/.kaggle/kaggle.json ou defina SGCC_DATASET_PATH para a pasta do dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Carregar dados e parâmetros do teste completo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Garantir raiz do projeto no path e no cwd (funciona em Colab/Kaggle e local)\n",
        "def _root():\n",
        "    cwd = os.path.abspath(os.getcwd())\n",
        "    for d in [cwd, os.path.join(cwd, \"..\"), os.path.join(cwd, \"..\", \"..\")]:\n",
        "        d = os.path.abspath(d)\n",
        "        if os.path.isdir(os.path.join(d, \"src\")) and os.path.isfile(os.path.join(d, \"train_baseline_pereira.py\")):\n",
        "            return d\n",
        "    return cwd\n",
        "\n",
        "ROOT = _root()\n",
        "if ROOT not in sys.path:\n",
        "    sys.path.insert(0, ROOT)\n",
        "if os.getcwd() != ROOT:\n",
        "    os.chdir(ROOT)\n",
        "\n",
        "from src.data.sgcc_loader import load_sgcc_from_path, train_test_split\n",
        "from train_baseline_pereira import get_dataset_path\n",
        "\n",
        "# Modo local: teste rápido (1 run, 2 épocas) para validar o fluxo. Colab/Kaggle: use False.\n",
        "try:\n",
        "    _run_local = not (_in_colab or _in_kaggle)\n",
        "except NameError:\n",
        "    _run_local = True  # se rodou a célula sem as anteriores\n",
        "QUICK_TEST = _run_local  # True = 1 run × 2 épocas; False = 3 runs × 100 épocas\n",
        "\n",
        "# Parâmetros do teste completo (como no artigo)\n",
        "N_RUNS_BASELINE = 1 if QUICK_TEST else 3   # 10 no artigo\n",
        "N_RUNS_HYBRID = 1 if QUICK_TEST else 3\n",
        "EPOCHS = 2 if QUICK_TEST else 100\n",
        "SEED = 42\n",
        "SEEDS = [0, 42, 123]\n",
        "VERBOSE = 1 if QUICK_TEST else 0  # 1 no quick test para ver progresso\n",
        "if QUICK_TEST:\n",
        "    print(\"Modo QUICK_TEST: 1 run × 2 épocas por cenário (para validar localmente).\")\n",
        "\n",
        "path = get_dataset_path(None)\n",
        "print(\"Carregando dataset SGCC...\")\n",
        "X, y = load_sgcc_from_path(path, seed=SEED, preprocessing=\"pereira\")\n",
        "print(f\"X.shape = {X.shape}, y.shape = {y.shape}\")\n",
        "print(f\"Normal: {(y==0).sum()}, Fraude: {(y==1).sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verificar se dados e modelo estão carregados corretamente\n",
        "\n",
        "Rode a célula abaixo para checar: **dados** (shape, classes, sem NaN) e **modelo baseline** (uma predição). Assim você confirma que o pipeline está certo antes do treino longo. (Para verificação completa incluindo híbrido, use `python scripts/verify_model_loading.py` na raiz do projeto.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verificação rápida: dados + modelo baseline\n",
        "import numpy as np\n",
        "from src.models.cnn import build_cnn\n",
        "\n",
        "# 1) Dados\n",
        "print(\"=== Dados (X, y) ===\")\n",
        "print(f\"  X.shape = {X.shape}  (esperado: (n, 148, 7, 1))\")\n",
        "print(f\"  y.shape = {y.shape}, classes: 0={(y==0).sum()}, 1={(y==1).sum()}\")\n",
        "print(f\"  X sem NaN: {not np.any(np.isnan(X))}\")\n",
        "ok_data = X.ndim == 4 and X.shape[1:] == (148, 7, 1) and y.shape[0] == X.shape[0]\n",
        "print(f\"  Formato OK: {ok_data}\\n\")\n",
        "\n",
        "# 2) Modelo baseline: construir e uma predição\n",
        "print(\"=== Modelo baseline (CNN) ===\")\n",
        "model = build_cnn(input_shape=(148, 7, 1))\n",
        "model.compile(optimizer=\"sgd\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "sample = X[:2]\n",
        "out = model.predict(sample, verbose=0)\n",
        "ok_model = out.shape == (2, 2) and np.allclose(out.sum(axis=1), 1.0)\n",
        "print(f\"  Entrada: {sample.shape} -> Saída: {out.shape} (esperado (2, 2))\")\n",
        "print(f\"  Modelo carrega e prediz OK: {ok_model}\")\n",
        "print(\"\\nTudo OK para treino.\" if (ok_data and ok_model) else \"Revise dados ou modelo.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Rodar Baseline (CNN) — 3 runs × 100 épocas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from train_baseline_pereira import run_scenario as run_baseline_scenario\n",
        "import numpy as np\n",
        "\n",
        "results_baseline = []\n",
        "for scenario in [\"no_balance\", \"ros\"]:\n",
        "    aucs, accs, times = [], [], []\n",
        "    for run in range(N_RUNS_BASELINE):\n",
        "        run_seed = SEEDS[run % len(SEEDS)]\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, stratify=True, seed=run_seed\n",
        "        )\n",
        "        # class_weight=True em no_balance evita colapso para a classe majoritária\n",
        "        res, _, _ = run_baseline_scenario(\n",
        "            scenario, X_train, y_train, X_test, y_test,\n",
        "            epochs=EPOCHS, verbose=VERBOSE, learning_rate=0.01, use_class_weight=True,\n",
        "            run_name=f\"baseline_{scenario}_run{run+1}\", out_dir=\".\"\n",
        "        )\n",
        "        aucs.append(res[\"auc\"])\n",
        "        accs.append(res[\"accuracy\"])\n",
        "        times.append(res[\"train_time_seconds\"])\n",
        "        auc_str = f\"{res['auc']:.4f}\" if not np.isnan(res[\"auc\"]) else \"nan\"\n",
        "        print(f\"  Baseline {scenario} run {run+1}/{N_RUNS_BASELINE} - AUC: {auc_str}, Acc: {res['accuracy']*100:.2f}%, Tempo: {res['train_time_seconds']:.0f}s\")\n",
        "    mean_auc = np.nanmean(aucs)\n",
        "    std_auc = np.nanstd(aucs, ddof=1) if len(aucs) > 1 else 0\n",
        "    if np.isnan(std_auc):\n",
        "        std_auc = 0.0\n",
        "    mean_acc = np.mean(accs) * 100\n",
        "    total_time = sum(times)\n",
        "    mean_time = np.mean(times)\n",
        "    results_baseline.append({\"scenario\": scenario, \"mean_auc\": mean_auc, \"std_auc\": std_auc, \"mean_acc\": mean_acc, \"total_time_s\": total_time, \"mean_time_s\": mean_time})\n",
        "    mean_auc_str = f\"{mean_auc:.4f}\" if not np.isnan(mean_auc) else \"nan\"\n",
        "    print(f\"  -> Media AUC: {mean_auc_str} +- {std_auc:.4f}, Media Acc: {mean_acc:.2f}% | Tempo total: {total_time:.0f}s ({mean_time:.0f}s/run)\")\n",
        "print(\"Baseline concluido.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Rodar Híbrido (CNN+VQC) — 3 runs × 100 épocas\n",
        "\n",
        "*(Mesmo número de runs do baseline para comparação justa. O circuito quântico é simulado em CPU; o treino da CNN usa GPU.)*\n",
        "\n",
        "**Execução em computador IBM:** defina no ambiente `QML_DEVICE=qiskit.ibmq`, `QML_IBMQ_BACKEND=...` e `IBMQX_TOKEN=...`. O código configura e valida o device antes do treino (se falhar, o erro aparece logo)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from train_hybrid_pereira import run_hybrid_scenario\n",
        "\n",
        "results_hybrid = []\n",
        "for scenario in [\"no_balance\", \"ros\"]:\n",
        "    aucs, accs, times = [], [], []\n",
        "    for run in range(N_RUNS_HYBRID):\n",
        "        run_seed = SEEDS[run % len(SEEDS)]\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, stratify=True, seed=run_seed\n",
        "        )\n",
        "        # use_class_weight=True (default) em no_balance; run_name para salvar checkpoint no Kaggle\n",
        "        res = run_hybrid_scenario(\n",
        "            scenario, X_train, y_train, X_test, y_test,\n",
        "            epochs=EPOCHS, verbose=VERBOSE, learning_rate=0.01,\n",
        "            run_name=f\"hybrid_{scenario}_run{run+1}\", out_dir=\".\"\n",
        "        )\n",
        "        aucs.append(res[\"auc\"])\n",
        "        accs.append(res[\"accuracy\"])\n",
        "        times.append(res[\"train_time_seconds\"])\n",
        "        auc_str = f\"{res['auc']:.4f}\" if not np.isnan(res[\"auc\"]) else \"nan\"\n",
        "        print(f\"  Hibrido {scenario} run {run+1}/{N_RUNS_HYBRID} - AUC: {auc_str}, Acc: {res['accuracy']*100:.2f}%, Tempo: {res['train_time_seconds']:.0f}s\")\n",
        "    mean_auc = np.nanmean(aucs)\n",
        "    std_auc = np.nanstd(aucs, ddof=1) if len(aucs) > 1 else 0\n",
        "    if np.isnan(std_auc):\n",
        "        std_auc = 0.0\n",
        "    mean_acc = np.mean(accs) * 100\n",
        "    total_time = sum(times)\n",
        "    mean_time = np.mean(times)\n",
        "    results_hybrid.append({\"scenario\": scenario, \"mean_auc\": mean_auc, \"std_auc\": std_auc, \"mean_acc\": mean_acc, \"total_time_s\": total_time, \"mean_time_s\": mean_time})\n",
        "    mean_auc_str = f\"{mean_auc:.4f}\" if not np.isnan(mean_auc) else \"nan\"\n",
        "    print(f\"  -> Media AUC: {mean_auc_str} +- {std_auc:.4f}, Media Acc: {mean_acc:.2f}% | Tempo total: {total_time:.0f}s ({mean_time:.0f}s/run)\")\n",
        "print(\"Hibrido concluido.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Tabela de comparação e referência do artigo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def _auc_str(mean_auc, std_auc):\n",
        "    \"\"\"Formata AUC para tabela; usa 'nan (colapso?)' quando AUC indefinida.\"\"\"\n",
        "    if np.isnan(mean_auc):\n",
        "        return \"nan (colapso?)\"\n",
        "    return f\"{mean_auc:.4f} +- {std_auc:.4f}\"\n",
        "\n",
        "rows = []\n",
        "for r in results_baseline:\n",
        "    rows.append({\n",
        "        \"Modelo\": \"Baseline (CNN)\",\n",
        "        \"Cenario\": r[\"scenario\"],\n",
        "        \"Media AUC\": _auc_str(r[\"mean_auc\"], r[\"std_auc\"]),\n",
        "        \"Media Acuracia (%)\": f\"{r['mean_acc']:.2f}\",\n",
        "        \"Runs\": N_RUNS_BASELINE,\n",
        "        \"Tempo total (s)\": round(r[\"total_time_s\"], 0),\n",
        "        \"Tempo medio/run (s)\": round(r[\"mean_time_s\"], 0)\n",
        "    })\n",
        "for r in results_hybrid:\n",
        "    rows.append({\n",
        "        \"Modelo\": \"Hibrido (CNN+VQC)\",\n",
        "        \"Cenario\": r[\"scenario\"],\n",
        "        \"Media AUC\": _auc_str(r[\"mean_auc\"], r[\"std_auc\"]),\n",
        "        \"Media Acuracia (%)\": f\"{r['mean_acc']:.2f}\",\n",
        "        \"Runs\": N_RUNS_HYBRID,\n",
        "        \"Tempo total (s)\": round(r[\"total_time_s\"], 0),\n",
        "        \"Tempo medio/run (s)\": round(r[\"mean_time_s\"], 0)\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "display(df)\n",
        "\n",
        "total_baseline = sum(r[\"total_time_s\"] for r in results_baseline)\n",
        "total_hybrid = sum(r[\"total_time_s\"] for r in results_hybrid)\n",
        "print(f\"Tempo total Baseline: {total_baseline/60:.1f} min | Tempo total Hibrido: {total_hybrid/60:.1f} min\")\n",
        "print(\"Referencia (Pereira & Saraiva 2021, 10 runs, 100 epocas):\")\n",
        "print(\"  No Balance: AUC 0,5162 +- 0,0045   Acuracia 91,59%\")\n",
        "print(\"  ROS:        AUC 0,6714 +- 0,0062   Acuracia 67,78%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvar resultados em CSV (download opcional)\n",
        "df.to_csv(\"colab_full_test_results.csv\", index=False)\n",
        "print(\"Resultados salvos em colab_full_test_results.csv\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
