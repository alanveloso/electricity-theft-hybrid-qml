# Detec√ß√£o de Furto de Energia com Redes Neurais H√≠bridas (CNN-VQC)

Este reposit√≥rio cont√©m a implementa√ß√£o oficial da pesquisa comparativa entre Redes Neurais Convolucionais Cl√°ssicas e uma abordagem H√≠brida Qu√¢ntica para detec√ß√£o de anomalias em dados desbalanceados de consumo de energia (Dataset SGCC).

## üéØ Objetivo
Avaliar se a utiliza√ß√£o de **Quantum Machine Learning (VQC)** como classificador final permite manter alta performance (AUC) reduzindo a necessidade de t√©cnicas agressivas de balanceamento de dados (como ROS/SMOTE), economizando mem√≥ria computacional.

## üèóÔ∏è Arquitetura
O projeto compara dois cen√°rios de balanceamento, **em ambos os modelos** (baseline e h√≠brido):

| Estrat√©gia    | Baseline (CNN)     | H√≠brido (CNN+VQC)   |
|---------------|--------------------|---------------------|
| **No Balance**| Treino nos dados desbalanceados (sem oversampling). | Idem: treino nos dados desbalanceados. |
| **ROS**       | Treino com Random Oversampling (duplica amostras da classe minorit√°ria at√© equilibrar). | Idem: mesmo `apply_ros` nos dados de treino. |

Ou seja: em cada estrat√©gia, baseline e h√≠brido usam exatamente o mesmo tratamento dos dados; a √∫nica diferen√ßa √© o modelo (CNN s√≥ vs CNN+VQC).

O VQC usa **4 qubits** por padr√£o (refer√™ncia do artigo: No Balance AUC ~0,52, ROS AUC ~0,67). Esse valor √© um bom equil√≠brio: simula√ß√£o r√°pida e compat√≠vel com hardware real. Escalar para mais qubits (ex.: 6‚Äì8) faz sentido s√≥ depois de ter resultados est√°veis (h√≠brido pr√≥ximo ou melhor que o baseline); a simula√ß√£o fica bem mais lenta e o treino muito mais pesado.

**Quem √© quem:** O **artigo** (Pereira & Saraiva) reporta resultados da **CNN cl√°ssica sozinha** (baseline). Neste reposit√≥rio comparamos essa baseline com o **h√≠brido QML** (CNN + VQC). Ou seja: "resultado do artigo" = baseline (sem qu√¢ntico); "QML" = nossa proposta (com circuito qu√¢ntico). Na corrida r√°pida abaixo, o baseline do artigo ficou melhor que o QML; o objetivo do projeto √© ver se o QML consegue **empatar ou ficar pr√≥ximo** do baseline (n√£o obrigatoriamente superar).

**Compara√ß√£o justa com a CNN:** o h√≠brido est√° em **modo padr√£o**: mesma receita do baseline (SGD lr=0.01, momentum=0, sem early stopping, limiar 0.5, class_weight s√≥ no No Balance). Modelo: CNN at√© Dense(128) ‚Üí Dense(4) ‚Üí VQC ‚Üí Dense(1), sem dropout/L2/gargalo extra; init do VQC em [-0.2œÄ, 0.2œÄ] para estabilidade. Assim a diferen√ßa de resultado reflete a arquitetura (VQC), n√£o truques de treino.

**Aprimoramentos opcionais** (para ablation): `train_hybrid_pereira.py --early-stopping --optimizer adam --momentum 0.9 --tune-threshold`. Use o notebook ou `--scenario both` para 100 √©pocas.

## üöÄ Como fazer funcionar

### 1. Ambiente
```bash
python3 -m venv .venv
source .venv/bin/activate   # Linux/macOS
# Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 2. Dataset SGCC ‚Äî duas op√ß√µes

**Op√ß√£o A: Download autom√°tico (recomendado)**  
Voc√™ n√£o precisa baixar nada √† m√£o; o script baixa sozinho se o Kaggle estiver configurado:

1. Crie uma conta em [Kaggle](https://www.kaggle.com) e aceite as regras do dataset [SGCC Dataset](https://www.kaggle.com/datasets/bensalem14/sgcc-dataset).
2. Autentica√ß√£o (uma das op√ß√µes):
   - **Arquivo:** em [Kaggle ‚Üí Account ‚Üí API](https://www.kaggle.com/settings), crie um token e coloque `kaggle.json` em `~/.kaggle/kaggle.json`.
   - **Vari√°veis de ambiente:** defina `KAGGLE_USERNAME` (seu usu√°rio) e `KAGGLE_KEY` ou `KAGGLE_API_TOKEN` (a chave do token). O script aceita `KAGGLE_API_TOKEN` e repassa como `KAGGLE_KEY` automaticamente.
3. Rode o treino (na primeira vez o dataset ser√° baixado automaticamente):
   ```bash
   export KAGGLE_USERNAME=seu_usuario
   export KAGGLE_API_TOKEN=sua_chave   # ou KAGGLE_KEY
   python train_sgcc_cnn.py
   ```

**Op√ß√£o B: Download manual**  
Se preferir baixar pelo site:

1. Acesse [SGCC Dataset](https://www.kaggle.com/datasets/bensalem14/sgcc-dataset) e clique em **Download**.
2. Descompacte o ZIP numa pasta (ex.: `data/sgcc-dataset`).
3. Rode o treino apontando para essa pasta:
   ```bash
   python train_sgcc_cnn.py data/sgcc-dataset
   ```
   Ou use a vari√°vel de ambiente:
   ```bash
   SGCC_DATASET_PATH=data/sgcc-dataset python train_sgcc_cnn.py
   ```

### 3. Treino

**Baseline Single CNN (Pereira & Saraiva 2021)** ‚Äî reprodu√ß√£o exata do artigo para compara√ß√£o:
- Pr√©-processamento: interpola√ß√£o linear (Eq. 1), 1035‚Üí1036 dias, reshape (148, 7, 1).
- Hiperpar√¢metros: SGD, batch 128, 100 √©pocas.
- Cen√°rios: **A (No Balance)** ou **B (ROS)**. M√©tricas: AUC, acur√°cia, matriz de confus√£o, tempo.
  ```bash
  python train_baseline_pereira.py --scenario no_balance   # Cen√°rio A
  python train_baseline_pereira.py --scenario ros         # Cen√°rio B
  python train_baseline_pereira.py --scenario both         # A e B (salva em results_baseline_pereira.json)
  python train_baseline_pereira.py --scenario both --max-epochs 3  # Teste r√°pido
  ```

**Script legado (Adam, EarlyStopping):** `python train_sgcc_cnn.py` ‚Äî modelo em `checkpoints/best_cnn_sgcc.keras`.

### Rodando no Kaggle
- **Entrada:** o dataset deve estar em `../input/nome-do-dataset/`. O script detecta o ambiente Kaggle e tenta `../input/bensalem14-sgcc-dataset` ou a primeira pasta em `../input/`; voc√™ pode definir `KAGGLE_INPUT_PATH` se o nome for outro.
- **Sa√≠da:** modelos, logs e gr√°ficos s√£o salvos em `./` (diret√≥rio de trabalho = `/kaggle/working`). Em cada execu√ß√£o s√£o gerados: `{run_name}_best_model.keras`, `{run_name}_training_log.csv`, `{run_name}_results.txt` e `{run_name}_auc_plot.png`.
- **Callbacks:** `ModelCheckpoint` (melhor modelo por `val_auc`) e `CSVLogger` (hist√≥rico por √©poca) s√£o adicionados automaticamente quando h√° `run_name` (o script de treino j√° passa isso). Assim, se o job travar no meio, voc√™ mant√©m o melhor modelo e o log at√© a √∫ltima √©poca.

### Simulador e hardware IBM (opcional)
O circuito VQC roda por padr√£o no simulador PennyLane (`default.qubit`). Voc√™ pode usar:

- **Simulador local no estilo IBM (Qiskit Aer)** ‚Äî n√£o precisa de token:
  ```python
  from src.models.hybrid import set_quantum_device
  set_quantum_device(device="qiskit.aer")  # pip install pennylane-qiskit
  ```
  Os simuladores **na nuvem** da IBM (ex. `ibmq_qasm_simulator`) foram desativados em 2024; o `qiskit.aer` roda na sua m√°quina e usa a mesma stack Qiskit/IBM. Para testar localmente: `python test_qiskit_aer.py` (requer `pip install pennylane-qiskit`).

- **Hardware real da IBM** ‚Äî precisa de conta e token em [IBM Quantum](https://quantum.ibm.com):
  ```python
  set_quantum_device(device="qiskit.ibmq", backend="ibm_brisbane", ibmqx_token="SEU_TOKEN")
  # ou export IBMQX_TOKEN=... e omitir ibmqx_token
  ```
  Instale: `pip install pennylane-qiskit qiskit-ibm-runtime`. Os backends dispon√≠veis aparecem no painel da IBM; o treino pode ter fila e limites de uso.

**Execu√ß√£o em computador IBM (ambiente IBM):** o c√≥digo pode ser configurado s√≥ por vari√°veis de ambiente; antes do treino h√≠brido o device √© validado. Defina no ambiente onde for rodar:
- `QML_DEVICE=qiskit.ibmq` (ou `qiskit.aer` para simulador local)
- `QML_IBMQ_BACKEND=ibm_brisbane` (ou o backend desejado)
- `IBMQX_TOKEN=seu_token`
Assim que o treino h√≠brido come√ßar, `configure_quantum_device_from_env()` e `validate_quantum_device()` garantem que o device est√° pronto; se algo falhar, o erro aparece antes do treino longo.

### Teste completo no Google Colab (GPU)
Para rodar o **teste completo** (3 runs baseline, 3 runs h√≠brido, 100 √©pocas) no Colab com GPU:

1. Abra o notebook **[notebooks/colab_full_test.ipynb](notebooks/colab_full_test.ipynb)** no Google Colab (upload ou abrir via GitHub).
2. Ative **Runtime ‚Üí Change runtime type ‚Üí GPU**.
3. Configure as credenciais do Kaggle (Secrets do Colab com `KAGGLE_USERNAME` e `KAGGLE_KEY`, ou upload do `kaggle.json`).
4. Execute as c√©lulas em ordem. O notebook clona o reposit√≥rio, instala depend√™ncias, baixa o SGCC e roda baseline e h√≠brido, gerando uma tabela de compara√ß√£o e um CSV.

### Verificar s√≥ a arquitetura da CNN (sem dados)
```bash
python -c "from src.models.cnn import build_paper_cnn; m = build_paper_cnn(); m.summary()"
```

---

1. Clone o reposit√≥rio:
   ```bash
   git clone [https://github.com/alanveloso/electricity-theft-hybrid-qml.git](https://github.com/alanveloso/electricity-theft-hybrid-qml.git)